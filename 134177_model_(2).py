# -*- coding: utf-8 -*-
"""134177_Model_(2).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MPCLJ02qStUtVlKW_bC5yFlklQUd-WuK
"""

import os
import cv2
import torch
import torch.utils.data as data
import torchvision.transforms as transforms
import numpy as np
import matplotlib.pyplot as plt
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torch.optim.lr_scheduler import ReduceLROnPlateau
from torchvision.models import segmentation


class CustomDataset(data.Dataset):
    def __init__(self, images_directory, masks_directory, image_transform=None, mask_transform=None, desired_size=(256, 256), augment=False, threshold=0.5):
        self.images_directory = images_directory
        self.masks_directory = masks_directory
        self.image_transform = image_transform
        self.mask_transform = mask_transform
        self.desired_size = desired_size
        self.augment = augment
        self.images = []
        self.masks = []

        for image_filename in os.listdir(images_directory):
            if image_filename.endswith(".jpg"):
                image_path = os.path.join(images_directory, image_filename)
                image = cv2.imread(image_path)

                mask_filename = os.path.splitext(image_filename)[0] + "_mask.png"
                mask_path = os.path.join(masks_directory, mask_filename)
                mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

                plt.figure(figsize=(8, 4))
                plt.subplot(1, 2, 1)
                plt.imshow(image)
                plt.title('Image')
                plt.subplot(1, 2, 2)
                plt.imshow(mask, cmap='gray')
                plt.title('Ground Truth Mask')
                plt.show()

                # Check and print image and mask dimensions
                print(f"Image shape before resizing: {image.shape}")
                print(f"Mask shape before resizing: {mask.shape}")

                # Resize the image and mask to the desired size
                image = cv2.resize(image, self.desired_size)
                mask = cv2.resize(mask, self.desired_size)

                # Ensure that the mask has a single channel
                if mask.shape[-1] > 1:
                    mask = mask.mean(axis=-1, keepdims=True)

                # Check and print image and mask dimensions after resizing
                print(f"Image shape after resizing: {image.shape}")
                print(f"Mask shape after resizing: {mask.shape}")

                _, mask = cv2.threshold(mask, threshold, 1, cv2.THRESH_BINARY)


                unique_values = np.unique(mask)
                print(f"Unique values in the mask after thresholding: {unique_values}")

                # Augmentation (applied only to the training set)
                if self.augment:
                    # Add your data augmentation logic here using torchvision transforms
                    # Example: random horizontal flip
                    if np.random.rand() > 0.5:
                        image = np.fliplr(image)
                        mask = np.fliplr(mask)

                self.images.append(image.copy())
                self.masks.append(mask.copy())

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        image = self.images[idx]
        mask = self.masks[idx]

        # Convert image to tensor
        image = self.image_transform(image) if self.image_transform else torch.from_numpy(image).permute(2, 0, 1)

        # Preprocess mask
        mask = self.mask_transform(mask) if self.mask_transform else torch.from_numpy(mask).to(torch.uint8)

        return image, mask

# Define data transforms for image and mask
image_transform = transforms.Compose([
    transforms.ToTensor(),
])

mask_transform = transforms.Compose([
    transforms.ToTensor(),
])

# Specify the desired size for images and masks
desired_size = (256, 256)

# Create a CustomDataset instance for training with data augmentation
train_dataset = CustomDataset(images_directory="/content/drive/MyDrive/IS PROJECT/datasets/training/training_images",
                              masks_directory="/content/drive/MyDrive/IS PROJECT/datasets/training/training_mask",
                              image_transform=image_transform,
                              mask_transform=mask_transform,
                              desired_size=desired_size,
                              augment=True)  # Apply data augmentation for training

# Create a CustomDataset instance for testing without data augmentation
test_dataset = CustomDataset(images_directory="/content/drive/MyDrive/IS PROJECT/datasets/testing/testing_images",
                             masks_directory="/content/drive/MyDrive/IS PROJECT/datasets/testing/testing_mask",
                             image_transform=image_transform,
                             mask_transform=mask_transform,
                             desired_size=desired_size,
                             augment=False)

# Create a CustomDataset instance for validation without data augmentation
val_dataset = CustomDataset(images_directory="/content/drive/MyDrive/IS PROJECT/datasets/validate/validate_images",
                             masks_directory="/content/drive/MyDrive/IS PROJECT/datasets/validate/validate_mask",
                             image_transform=image_transform,
                             mask_transform=mask_transform,
                             desired_size=desired_size,
                             augment=False)

# Example usage in DataLoader
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)
val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=8, shuffle=False)

# ... rest of the code ...

from google.colab import drive
drive.mount('/content/drive')

import torch.optim as optim
from torch.utils.data import DataLoader

device = torch.device("cpu")

train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)
val_loader = DataLoader(val_dataset, batch_size = 8, shuffle = False)

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.optim.lr_scheduler import ReduceLROnPlateau
from torchvision.models import segmentation

# Custom head for binary segmentation
class CustomDeepLabHead(nn.Sequential):
    def __init__(self, in_channels, out_channels, dropout_prob=0.5):
        super(CustomDeepLabHead, self).__init__(
            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=True),
            nn.Dropout2d(p=dropout_prob)  # Add dropout layer
        )

# Define the DeepLabV3 model with dropout
class DeepLabV3Model(nn.Module):
    def __init__(self, in_channels, out_channels, dropout_prob=0.5):
        super(DeepLabV3Model, self).__init__()

        # Load the pre-trained DeepLabV3 model
        self.deeplabv3_model = segmentation.deeplabv3_resnet50(pretrained=True)

        # Modify the model for binary segmentation (1 channel) and add dropout
        in_channels_resnet = 2048  # Number of input channels from the backbone
        self.deeplabv3_model.classifier = CustomDeepLabHead(in_channels_resnet, out_channels, dropout_prob)

    def forward(self, x):
        return self.deeplabv3_model(x)

# Define the DeepLabV3Model
in_channels = 3  # Assuming RGB images
out_channels = 1  # Output is a single-channel mask
dropout_prob = 0.5  # Adjust dropout probability as needed

model = DeepLabV3Model(in_channels, out_channels, dropout_prob)
print(model)

# Define the DiceBCELoss
class DiceBCELoss(nn.Module):
    def __init__(self, weight_bce=1.0, weight_dice=1.0, smooth=1.0):
        super(DiceBCELoss, self).__init__()
        self.weight_bce = weight_bce
        self.weight_dice = weight_dice
        self.smooth = smooth

    def forward(self, pred, target):
        bce_loss = nn.BCEWithLogitsLoss()(pred, target)

        # Dice Loss calculation
        intersection = (pred * target).sum(dim=(2, 3))
        union = pred.sum(dim=(2, 3)) + target.sum(dim=(2, 3)) + self.smooth
        dice = (2.0 * intersection + self.smooth) / union
        dice_loss = 1.0 - dice.mean()

        # Combine BCE and Dice Loss
        loss = self.weight_bce * bce_loss + self.weight_dice * dice_loss
        return loss

# Example usage
criterion = DiceBCELoss(weight_bce=1.0, weight_dice=1.0, smooth=1.0)
optimizer = optim.Adam(model.parameters(), lr=0.001)

for inputs, masks in train_loader:
    try:
        # Print shapes before transformations
        print("Input shape before:", inputs.shape)
        print("Mask shape before:", masks.shape)

        # Move to device
        inputs, masks = inputs.to(device), masks.to(device)

        # Print shapes after moving to device
        print("Input shape after:", inputs.shape)
        print("Mask shape after:", masks.shape)

        # Rest of the training loop...

    except Exception as e:
        print("Error during training loop:", e)
        break  # Stop the loop on error to investigate further

# Add gradient clipping
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

import torch
import torch.nn.functional as F
from torch.optim.lr_scheduler import ReduceLROnPlateau
import matplotlib.pyplot as plt

# ... (previous code)
# Initialize lists to store batch loss and accuracy values
batch_loss_list = []
batch_accuracy_list = []

def calculate_accuracy(predictions, targets, threshold=0.5):
    """
    Calculate accuracy based on binary predictions and targets.

    Args:
    - predictions: Tensor, model predictions
    - targets: Tensor, ground truth labels
    - threshold: Float, threshold for binary classification

    Returns:
    - accuracy: Float, accuracy value
    """
    predictions = (predictions > threshold).float()
    correct = (predictions == targets).float()
    accuracy = correct.sum() / targets.numel()
    return accuracy.item()

num_epochs = 10

model.to(device)
optimizer = optim.Adam(model.parameters(), lr=0.0001)
scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.1, verbose=True)


# Learning rate scheduler

model.train()

for epoch in range(num_epochs):
    for inputs, masks in train_loader:
        inputs, masks = inputs.to(device), masks.to(device)

        optimizer.zero_grad()

        outputs = model(inputs)['out']  # Accessing the 'out' key from the model output
        outputs = torch.sigmoid(outputs)

        targets_resized = F.interpolate(masks, size=(256, 256), mode='nearest')
        loss = criterion(outputs, targets_resized)

        accuracy = calculate_accuracy(outputs, targets_resized)

        batch_loss_list.append(loss.item())
        batch_accuracy_list.append(accuracy)

        print(f"Epoch {epoch+1}/{num_epochs}, Batch Loss: {loss.item()}, Batch Accuracy: {accuracy}")

        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        optimizer.step()

        model.eval()
        val_loss_list = []
        val_accuracy_list = []


    # ... (rest of the code)

    # Optionally, validate the model on the validation set
    with torch.no_grad():
        model.eval()
        for val_inputs, val_masks in val_loader:
            val_inputs, val_masks = val_inputs.to(device), val_masks.to(device)

            val_outputs = model(val_inputs)['out']  # Accessing the 'out' key from the model output
            val_outputs_sigmoid = torch.sigmoid(val_outputs)
            val_masks_resized = F.interpolate(val_masks, size=(256, 256), mode='nearest')
            val_loss = criterion(val_outputs, val_masks_resized)
            val_accuracy = calculate_accuracy(val_outputs_sigmoid, val_masks_resized)
            val_loss_list.append(val_loss.item())
            val_accuracy_list.append(val_accuracy)

            avg_val_loss = sum(val_loss_list) / len(val_loss_list)
            avg_val_accuracy = sum(val_accuracy_list) / len(val_accuracy_list)

            print(f"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}, Validation Loss: {avg_val_loss}, Validation Accuracy: {avg_val_accuracy}")
            scheduler.step(avg_val_loss)

plt.figure(figsize=(12, 4))

# Plot Batch Loss
plt.subplot(1, 2, 1)
plt.plot(batch_loss_list, label='Batch Loss', color='blue')
plt.xlabel('Batch')
plt.ylabel('Loss')
plt.title('Batch Loss')
plt.legend()

# Plot Batch Accuracy
plt.subplot(1, 2, 2)
plt.plot(batch_accuracy_list, label='Batch Accuracy', color='green')
plt.xlabel('Batch')
plt.ylabel('Accuracy')
plt.title('Batch Accuracy')
plt.legend()

plt.tight_layout()
plt.show()

import os

model_file_path = '134177-Model(2).pth'

file_size = os.path.getsize(model_file_path)

if file_size > 0:
    print(f"The model file '{model_file_path}' is not empty.")
else:
    print(f"The model file '{model_file_path}' is empty or does not exist.")

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

model.eval()
all_predictions = []
all_targets = []

with torch.no_grad():
    for test_inputs, test_masks in test_loader:
        test_inputs, test_masks = test_inputs.to(device), test_masks.to(device)

        test_outputs = model(test_inputs)['out']  # Accessing the 'out' key from the model output
        test_outputs_sigmoid = torch.sigmoid(test_outputs)
        test_masks_resized = F.interpolate(test_masks, size=(256, 256), mode='nearest')

        # Convert to numpy arrays
        predictions = (test_outputs_sigmoid > 0.5).float().cpu().numpy().flatten()
        targets = test_masks_resized.cpu().numpy().flatten()

        all_predictions.extend(predictions)
        all_targets.extend(targets)

# Convert lists to numpy arrays
all_predictions = np.array(all_predictions)
all_targets = np.array(all_targets)

# Calculate metrics
accuracy = accuracy_score(all_targets, all_predictions)
precision = precision_score(all_targets, all_predictions)
recall = recall_score(all_targets, all_predictions)
f1 = f1_score(all_targets, all_predictions)

print(f"Test Accuracy: {accuracy:.4f}")
print(f"Test Precision: {precision:.4f}")
print(f"Test Recall: {recall:.4f}")
print(f"Test F1 Score: {f1:.4f}")

torch.save(model, '134177-Model(2).pth')

from sklearn.metrics import confusion_matrix
conf_matrix = confusion_matrix(all_targets, all_predictions)
print("Confusion Matrix:")
print(conf_matrix)

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Assuming all_targets and all_predictions are your true labels and predicted labels, respectively
conf_matrix = confusion_matrix(all_targets, all_predictions, normalize='true')

# Plot confusion matrix with purple color
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='.2%', cmap='Purples', xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])
plt.title('Normalized Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

import os
import torch

# Specify the full path for saving and loading
model_path = '/content/drive/MyDrive/Colab Notebooks/134177-Model(6).pth'

# Save the model
torch.save(model, model_path)